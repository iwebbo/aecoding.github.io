<!DOCTYPE html>
<html lang="fr">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>LLM.io — Multi-Provider Chat Application IA</title>
  <link rel="stylesheet" href="../assets/css/style.css" />
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css" />
  <style>
      .logo-img {
      height: 120px;
      width: auto;
      object-fit: contain;
      }
</style>
</head>

<body>
<div class="container">
<header class="site-header">
  <nav>
    <a href="../index.html" class="logo">        
      <img src="../assets/img/llm.png" alt="A&ECoding Logo" class="logo-img" />
      </a>
    <ul>
      <li><a href="../index.html">Home</a></li>
      <li><a href="theai.html">THEAI.io</a></li>
      <li><a href="../index.html#about">RAG.io</a></li>
      <li><a href="../index.html#contact">Contact</a></li>
    </ul>
  </nav>
</header>

<!-- HERO -->
<section class="hero">
  <h1>LLM.io</h1>
  <p class="subtitle">
    Multi-Provider Chat Application.
  </p>

  <div class="hero-cta">
    <a href="#" class="btn-primary">Presentation</a>
    <a href="https://github.com/iwebbo/LLM.io" class="btn-secondary" target="_blank">Code source</a>
  </div>
</section>

<!-- PRESENTATION -->
<section class="hero-glass">
  <h2>Build with</h2>
    <div class="tech-icons">
    <i class="fa-brands fa-docker" title="Docker"></i>
    <i class="fa-brands fa-linux" title="Linux"></i>
    <i class="fa-brands fa-python" title="Python"></i>
    <i class="fa-brands fa-github" title="Github"></i>
    <i class="fa-brands fa-react" title="React"></i>
  </div>
</section>


<section class="products" aria-label="Nos applications principales">
  <article class="product-card" id="theai" tabindex="0">
    <h2>Current Features</h2>
    <ul class="features-list">
      <li><strong>Multi-Provider :</strong> 13+ providers with automatic fallback</li>
      <li><strong>SSE Streaming :</strong> Real-time responses with auto-reconnect</li>
      <li><strong>Temperature Control :</strong> Per-conversation adjustment (0.0-2.0)</li>
      <li><strong>Prompt Templates :</strong> Create, share, use {{placeholders}}</li>
      <li><strong>Token Analytics :</strong> Dashboard with daily/provider/model totals</li>
      <li><strong>Conversation History :</strong> PostgreSQL storage with full-text search	</li>
      <li><strong>Export Conversations :</strong> Markdown, JSON, HTML</li>
    </ul>
  </article>

  <article class="product-card" id="theai" tabindex="0">
    <h2>Advanced Features</h2>
    <ul class="features-list">
      <li><strong>Chain of Thought :</strong> Auto-detection for reasoning models (o1-preview, DeepSeek-R1, etc.)</li>
      <li><strong>Deep Reasoning Mode :</strong> Enables high max_tokens for long reasoning</li>
      <li><strong>Model Auto-discovery :</strong> Dynamically fetches available models per provider</li>
      <li><strong>Health Checks :</strong> Connection testing with latency monitoring</li>
      <li><strong>Rate Limiting :</strong> Abuse protection (60 req/min, configurable)</li>
      <li><strong>Multi-origin CORS :</strong> Simultaneous frontend/mobile/desktop support</li>
    </ul>
  </article>

  <article class="product-card" id="theai" tabindex="0">
    <h2>Providers Supported</h2>
    <ul class="features-list">
      <li><strong>OpenAI :</strong> GPT-4o, GPT-4-turbo, o1-preview, o1-mini.</li>
      <li><strong>Anthropic Claude :</strong> Claude 3.5 Sonnet, Claude 3 Opus</li>
      <li><strong>Google Gemini :</strong> Gemini 1.5 Pro/Flash, Gemini 2.0</li>
      <li><strong>OpenRouter :</strong> 200+ models (free + paid)</li>
      <li><strong>xAI Grok :</strong> Grok-3, Grok-3-mini, Grok-3-vision</li>
      <li><strong>Groq :</strong> 	Mixtral, LLaMA 3, Gemma</li>
      <li><strong>HuggingFace :</strong> Zephyr, Mistral, LLaMA 2</li>
      <li><strong>Ollama :</strong> ollama pull llama3</li>
      <li><strong>LM Studio :</strong> GUI app</li>
      <li><strong>vLLM :</strong> Python + CUDA</li>
      <li><strong>LMDeploy :</strong> Python + TurboMind</li>
      <li><strong>Oobabooga :</strong> Web UI</li>
    </ul>
  </article>
</section>

  <section class="about" aria-label="Présentation de aecoding.io">
    <h2>About</h2>
      <p>This project is licensed under the MIT License - see the LICENSE file for details.</p>
  </section>

  <section class="about" aria-label="Contact">
    <h2>Contact me</h2>
    <p>Built with ❤️ for system administrators and DevOps engineers</p>
    <p>For questions, suggestions, or support, please open an issue or contact the maintainers.<a href="mailto:l.kieran95@gmail.com">@me</a>.</p>
  </section>


<footer>
  <p>© 2025 aecoding.io — Tous droits réservés.</p>
</footer>
</div>
</body>
</html>
